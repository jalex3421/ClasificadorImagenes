{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se implementarán dos modelos de ML como son regresión logísitica y redes neuronales.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos hemos inclinado por RL en detrimento de SVM pues el número de características es bastante superior al número de ejemplos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder hacer regresión logística de manera óptima, se ha de comprobar en el momento cual es nuestra singal objetivo y poner 1 en esas. 0 en otro caso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Función$ $para$ $transformar$ $Y$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devolverDiccionarioEtiquetas():\n",
    "    \n",
    "    diccionarioValores = {}\n",
    "    diccionarioValores['00000'] = 'VelocidadMaxima20'\n",
    "    diccionarioValores['00001'] = 'VelocidadMaxima30'\n",
    "    diccionarioValores['00002'] = 'VelocidadMaxima50'\n",
    "    diccionarioValores['00003'] = 'VelocidadMaxima60'\n",
    "    diccionarioValores['00004'] = 'VelocidadMaxima70'\n",
    "    diccionarioValores['00005'] = 'VelocidadMaxima80'\n",
    "    diccionarioValores['00006'] = 'FinVelocidadMaxima80'\n",
    "    diccionarioValores['00007'] = 'VelocidadMaxima100'\n",
    "    diccionarioValores['00008'] = 'VelocidadMaxima120'\n",
    "    diccionarioValores['00009'] = 'AdelantamientoProhibido'\n",
    "    diccionarioValores['00010'] = 'AdelantamientoProhibidoParaCamiones'\n",
    "\n",
    "    diccionarioValores['00011'] = 'InterseccionConPrioridad'\n",
    "    diccionarioValores['00012'] = 'CalzadaConPrioridad'\n",
    "    diccionarioValores['00013'] = 'CedaElPaso'\n",
    "    diccionarioValores['00014'] = 'DetencionObligatoria'\n",
    "    diccionarioValores['00015'] = 'CirculacionProhibida'\n",
    "    diccionarioValores['00016'] = 'EntradaProhibidaAVehiculosMercancias'\n",
    "    diccionarioValores['00017'] = 'EntradaProhibida'\n",
    "    diccionarioValores['00018'] = 'OtrosPeligros'\n",
    "    diccionarioValores['00019'] = 'CurvaPeligrosaHaciaLaIzquierda'\n",
    "    diccionarioValores['00020'] = 'CurvaPeligrosaHaciaLaDerecha'\n",
    "\n",
    "    diccionarioValores['00021'] = 'CurvasPeligrosasHaciaLaIzquierda'\n",
    "    diccionarioValores['00022'] = 'PerfilIrregular'\n",
    "    diccionarioValores['00023'] = 'PavimentoDeslizante'\n",
    "    diccionarioValores['00024'] = 'EstrechamientoCalzadaPorDerecha'\n",
    "    diccionarioValores['00025'] = 'Obras'\n",
    "    diccionarioValores['00026'] = 'Semaforos'\n",
    "    diccionarioValores['00027'] = 'PasoDePeatones'\n",
    "    diccionarioValores['00028'] = 'Kids'\n",
    "    diccionarioValores['00029'] = 'EntradaProhibidasCiclos'\n",
    "    diccionarioValores['00030'] = 'PavimentoDeslizanteNieveHielo'\n",
    "\n",
    "    diccionarioValores['00031'] = 'PasoDeAnimalesEnLibertad'\n",
    "    diccionarioValores['00032'] = 'FinDeProhibiciones'\n",
    "    diccionarioValores['00033'] = 'SentidoObligatorioDerecha'\n",
    "    diccionarioValores['00034'] = 'SentidoObligatorioIzquierda'\n",
    "    diccionarioValores['00035'] = 'SentidoObligatorioArriba'\n",
    "    diccionarioValores['00036'] = 'DirPermitidasArribaDerecha'\n",
    "    diccionarioValores['00037'] = 'DirPermitidasArribaIzquierda'\n",
    "    diccionarioValores['00038'] = 'PasoObligatorioDerecha'\n",
    "    diccionarioValores['00039'] = 'PasoObligatorioizquierda'\n",
    "    diccionarioValores['00040'] = 'InterseccionSentidoObligatorioGiratorio'\n",
    "\n",
    "\n",
    "    diccionarioValores['00041'] = 'FinProhibicionAdelantamiento'\n",
    "    diccionarioValores['00042'] = 'FinProhibicionAdelantamientoCamiones'\n",
    "    \n",
    "    return diccionarioValores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformarY():\n",
    "    print(\"Y falta por transformar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación de las cosas..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris #dataset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccionario  = devolverDiccionarioEtiquetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIDEA POR ENCIMA....\\n#Y = transformarY(Y)\\nfor k,v in diccionario.items():\\n    Y = nuevaY\\nX, y = load_iris(return_X_y=True)\\nclf = LogisticRegression(random_state=0).fit(X, y)\\nprediccion = clf.predict(X[:2, :])\\nclf.predict_proba(X[:2, :])\\nscore = clf.score(X, y)\\nprint(f\"La precision del clasificador es : {score}\")\\nprint(f\"La prediccion es : {prediccion}\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "IDEA POR ENCIMA....\n",
    "#Y = transformarY(Y)\n",
    "for k,v in diccionario.items():\n",
    "    Y = nuevaY\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "prediccion = clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "score = clf.score(X, y)\n",
    "print(f\"La precision del clasificador es : {score}\")\n",
    "print(f\"La prediccion es : {prediccion}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precision del clasificador es : 0.96\n",
      "La prediccion es : [0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alemt\\anaconda3\\envs\\py37vision\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\alemt\\anaconda3\\envs\\py37vision\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "prediccion = clf.predict(X[:2, :])\n",
    "clf.predict_proba(X[:2, :])\n",
    "score = clf.score(X, y)\n",
    "print(f\"La precision del clasificador es : {score}\")\n",
    "print(f\"La prediccion es : {prediccion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alemt\\anaconda3\\envs\\py37vision\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Salida con multiples clases, es decir  los vectores poseeran valores de 0 y 1\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "# Aplica el fit_transform de scikit a y para obtener el nuevo y_onehot\n",
    "y_onehot = encoder.fit_transform(y.reshape(-1,1))\n",
    "\n",
    "#esto quiere decir que hay 'n' posibles clases. Se pondra un 1 en la clase que participa, y 0 en la clase que no participa.\n",
    "#La participacion va por  'registros'\n",
    "#Para mas info: https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
    "y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    bias = np.ones(m).reshape(-1,1)\n",
    "    \n",
    "    # Añadimos la columna de unos a X para obtener a1\n",
    "    a1 = np.hstack((bias,X))\n",
    "    \n",
    "    # Calculamos z2 -> ten en cuenta que a1 tiene tantas filas como ejemplos y columnas como atributos + 1\n",
    "    # Por otro lado, theta1 tiene tantas filas como neuronas en la capa oculta y columnas como atributos + 1\n",
    "    z2 = a1*theta1.T\n",
    "    \n",
    "    # Añadimos la columna de unos a la sigmoide de z2 (que es a2) para obtener el a2 definitivo\n",
    "    a2 = np.hstack((np.ones(z2.shape[0]).reshape(-1,1),sigmoid(z2)))\n",
    "    \n",
    "    # Calculamos z3\n",
    "    z3 = a2*theta2.T\n",
    "    \n",
    "    # Obtenemos la salida final en h\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y):\n",
    "    m = X.shape[0]\n",
    "    # Utilizamos las matrices de numpy por facilidad: * es el producto de matrices y np.multiply elemento por elemento\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # desempaquetamos las matrices con los parámetros para cada capa\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # Ejecutamos las propagación hacia adelante para obtener las salidas para cada ejemplo\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Calculamos el coste\n",
    "    J = (1/m)*(np.sum(np.multiply((-y),np.log(h))-np.multiply((1-y),np.log(1-h))))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 5), (3, 26))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuración inicial\n",
    "input_size = X.shape[1] #numero de caracteristicas de X\n",
    "hidden_size = 25\n",
    "num_labels = 3\n",
    "np.random.seed(123456789)\n",
    "\n",
    "# Inicializamos los parámetros de la red aleatoriamente\n",
    "# El tamaño del array es el tamaño de las dos matrices de pesos concatenadas\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "# Podemos desempaquetar los parámetros que acabamos de inicializar igual que lo hacemos en la función de coste\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "# Veamos si los tamaños de las matrices theta1 y theta2 son correctos\n",
    "theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costReg(params, input_size, hidden_size, num_labels, X, y, lambda_reg):\n",
    "    m = X.shape[0]\n",
    "    # Utilizamos las matrices de numpy por facilidad: * es el producto de matrices y np.multiply elemento por elemento\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # desempaquetamos las matrices con los parámetros para cada capa, obtener theta1 y theta2\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # Ejecutamos las propagación hacia adelante para obtener las salidas para cada ejemplo\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Calculamos el coste\n",
    "    J = (1/m)*(np.sum(np.multiply((-y),np.log(h))-np.multiply((1-y),np.log(1-h))))\n",
    "    \n",
    "    # Es decir, la suma de los parámetros al cuadrado sin considerar la primera columna en ninguna de las dos matrices de parámetros\n",
    "    J += (lambda_reg/(2*m))*(np.sum(np.sum(np.multiply(theta1,theta1))+np.sum(np.multiply(theta2,theta2))))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    g = sigmoid(z)\n",
    "    return np.multiply(g,(1-g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropReg(params, input_size, hidden_size, num_labels, X, y, lambda_reg):\n",
    "    ###################################################################\n",
    "    # Copiar aquí el código de la función de coste con regularización #\n",
    "    ###################################################################\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    # Utilizamos las matrices de numpy por facilidad: * es el producto de matrices y np.multiply elemento por elemento\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # desempaquetamos las matrices con los parámetros para cada capa, obtener theta1 y theta2\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # Ejecutamos las propagación hacia adelante para obtener las salidas para cada ejemplo\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # Calculamos el coste\n",
    "    J = (1/m)*(np.sum(np.multiply((-y),np.log(h))-np.multiply((1-y),np.log(1-h))))\n",
    "    \n",
    "    # Es decir, la suma de los parámetros al cuadrado sin considerar la primera columna en ninguna de las dos matrices de parámetros\n",
    "    J += (lambda_reg/(2*m))*(np.sum(np.sum(np.multiply(theta1,theta1))+np.sum(np.multiply(theta2,theta2))))\n",
    "    \n",
    "     ############################\n",
    "    # Comienza Backpropagation #\n",
    "    ############################\n",
    "    # Inicializamos los acumuladores delta1  y delta2 a ceros, con las dismensiones de los theta1 y theta2\n",
    "    # tendrán dimensiones (25, 401) y (10, 26), respectivamente\n",
    "    delta1 = np.zeros(theta1.shape)\n",
    "    delta2 = np.zeros(theta2.shape)\n",
    "    \n",
    "    # Aunque podríamos vectorizarlo vamos a hacerlo para cada ejemplo\n",
    "    for t in range(m):\n",
    "        # Obtenemos lo que necesitamos del ejemplo (cálculos obtenidos en la propagación hacia adelante)\n",
    "        # Para usar las fórmulas tal y como aparecen, vamos a coger todos los vectores en forma columna (resahpe(-1,1))\n",
    "        a1t = a1[t,:].reshape(-1, 1)  # (401, 1)\n",
    "        z2t = z2[t,:].reshape(-1, 1)  # (25, 1)\n",
    "        a2t = a2[t,:].reshape(-1, 1)  # (26, 1)\n",
    "        ht = h[t,:].reshape(-1, 1)  # (10, 1)\n",
    "        yt = y[t,:].reshape(-1, 1)  # (10, 1)\n",
    "        \n",
    "        # Calculamos el error en la capa de salida (delta3), almacenar en d3t\n",
    "        d3t = ht - yt\n",
    "        \n",
    "        # Para calcular el error en la capa oculta (delta2) necesitamos añadir un uno al inicio del vector z2t\n",
    "        # Almacenar en z2t\n",
    "        z2t = np.vstack((1,z2t))\n",
    "        \n",
    "        # Calculamos d2 a partir del error de la capa de salida, los parámetros en theta2 y el gradiente de z2t (guardar en d2t)\n",
    "        # <RELLENAR>\n",
    "        d2t = np.multiply(theta2.T*d3t,sigmoid_gradient(z2t))\n",
    "        \n",
    "        # Ya podemos calcular los gradientes a partir de los errores\n",
    "        # Para calcular el gradiente de los theta1, tenemos en cuenta el error en la capa oculta d2\n",
    "        # Acumular el gradiente del ejemplo en delta1 y delta2\n",
    "        delta1 += d2t[1:]*a1t.T\n",
    "        delta2 += d3t*a2t.T\n",
    "    \n",
    "    # Calculamos el gradiente finalmente dividiendo entre el número de ejemplos\n",
    "    delta1 = delta1/m\n",
    "    delta2 = delta2/m\n",
    "    \n",
    "    # Añadimos el término de regularización en delta1 y delta2 (no regularizar el bias)\n",
    "    \n",
    "    delta1[:,1:] += lambda_reg*theta1[:,1:]/m\n",
    "    delta2[:,1:] += lambda_reg*theta2[:,1:]/m\n",
    "    \n",
    "    # Para pasar los gradientes a minimize los ponemos en un vector\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9785097686071078 (203,)\n"
     ]
    }
   ],
   "source": [
    "J, grad = backpropReg(params, input_size, hidden_size, num_labels, X, y_onehot, lambda_reg)\n",
    "print(J, grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la red y clasificación\n",
    "\n",
    "Ahora ya estamos listos para entrenar la red y usarla para hacer predicciones. Para entrenarla, utilizamos el método `minimize`de scipy, indicándole que backpropReg es la función que calcula el coste y los gradientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.6896462786024466\n",
       "     jac: array([-1.32530111e-05, -9.16119551e-04,  8.57243828e-05, -1.91261410e-03,\n",
       "       -9.26821562e-04,  7.35148300e-04, -7.54388754e-03, -3.57031065e-03,\n",
       "       -6.57811952e-03, -2.63905651e-03, -6.35688350e-04,  3.33184616e-02,\n",
       "        1.58553342e-02,  2.79649956e-02,  6.57434402e-03, -6.26310726e-05,\n",
       "        4.30275491e-03,  2.07223974e-03,  4.19293378e-03,  2.08483533e-03,\n",
       "        1.86393611e-03, -7.10411809e-04, -2.71121240e-04, -3.76306038e-04,\n",
       "        2.01769527e-04, -1.99606168e-04, -1.92857240e-03, -5.60916998e-04,\n",
       "       -2.50659394e-03, -1.24645487e-03,  1.16588045e-05, -1.58643345e-02,\n",
       "       -7.52738586e-03, -1.31865991e-02, -5.01175298e-03, -2.06860574e-03,\n",
       "       -7.71195290e-03, -5.00213364e-03, -2.64627760e-03, -2.49958696e-04,\n",
       "        5.56457868e-04, -1.10388045e-02, -5.07705971e-03, -1.07110222e-02,\n",
       "       -4.14911667e-03, -3.17568975e-05,  2.68323831e-03,  8.48762432e-04,\n",
       "        2.04448776e-03,  3.64944774e-04,  1.75561463e-03,  4.28561367e-03,\n",
       "        2.90537072e-03,  1.11311362e-03,  1.52037378e-04, -1.34917935e-03,\n",
       "       -3.43529841e-03, -2.62099313e-03, -3.68140736e-04,  2.68232852e-04,\n",
       "       -4.98800554e-04,  1.28230199e-03, -4.48664436e-04,  3.29839694e-03,\n",
       "        7.73169211e-04, -8.85740115e-04,  3.07537642e-02,  1.30356067e-02,\n",
       "        3.01044908e-02,  1.06510865e-02, -6.16950600e-04, -2.72616612e-03,\n",
       "       -1.54772542e-03, -9.50569547e-04,  1.52299965e-05, -1.48381299e-05,\n",
       "       -3.97190617e-03, -1.61329809e-03, -2.57607320e-03, -6.48538913e-04,\n",
       "       -1.30099425e-03, -2.98113338e-03, -4.10840569e-03,  1.54155059e-03,\n",
       "        8.93723745e-04, -1.28390121e-03, -4.93363150e-03, -3.17896232e-03,\n",
       "       -1.49505486e-03, -1.81459168e-04,  1.27864268e-04,  1.21999640e-03,\n",
       "        6.07316728e-04,  6.00576300e-04, -6.17819734e-05, -1.90056975e-03,\n",
       "       -5.45390749e-03, -3.87048092e-03, -1.17823933e-03,  1.84518562e-04,\n",
       "        4.62886407e-04, -4.92417450e-03, -2.27278056e-03, -3.58149447e-03,\n",
       "       -1.12324985e-03, -1.40750009e-03, -2.99449509e-03, -1.97389771e-03,\n",
       "       -5.10591941e-04,  6.93886604e-05, -1.14827412e-03, -3.64412607e-03,\n",
       "       -2.68390443e-03, -9.32493750e-04, -2.85882055e-04,  8.82842958e-04,\n",
       "       -1.09091747e-02, -4.56578928e-03, -9.57875533e-03, -3.88128193e-03,\n",
       "       -5.94066740e-05, -6.17659140e-04, -7.13643515e-04,  3.47215123e-04,\n",
       "       -1.22415059e-04,  1.72718702e-03, -3.78646318e-04,  4.09769774e-04,\n",
       "       -1.83568985e-03, -3.85741486e-04,  4.34166514e-04, -7.49794112e-04,\n",
       "        1.25195513e-04, -1.95385337e-03,  1.79133662e-04, -8.38622663e-04,\n",
       "        3.40671696e-04, -2.02268963e-03, -1.23097079e-03, -4.71003016e-04,\n",
       "       -5.98938936e-04, -8.94788718e-04, -1.26434093e-04, -2.28219100e-03,\n",
       "        9.91654978e-05, -1.07751162e-03,  2.38413718e-04, -1.51738650e-03,\n",
       "       -9.16297144e-04,  2.45424886e-04,  2.25884069e-03,  5.01691362e-03,\n",
       "        2.77986666e-03, -2.66231421e-04,  4.45071840e-03,  3.39058730e-03,\n",
       "       -1.38923304e-05,  2.62794407e-03,  6.12789764e-05,  3.27532780e-03,\n",
       "        4.37972810e-04,  2.31888559e-03,  3.51877544e-03,  3.19645451e-03,\n",
       "        2.62250605e-03,  5.28667941e-03,  1.59616451e-03, -1.54248346e-03,\n",
       "        2.17300559e-03,  2.18250016e-03,  2.44199920e-03,  1.42704381e-03,\n",
       "        3.03782851e-04,  2.21627979e-03,  3.30261298e-03,  2.25739109e-04,\n",
       "        2.78849549e-03, -2.10087589e-03, -1.51207310e-03, -1.87778513e-03,\n",
       "        7.52208835e-04, -1.44610813e-03, -2.87918238e-03, -2.40766751e-03,\n",
       "       -2.84425394e-03, -5.38105159e-04, -2.87075894e-04, -1.25343462e-04,\n",
       "       -2.43954877e-03,  7.50584742e-05,  7.47325625e-05, -3.01225851e-03,\n",
       "        5.37457480e-05,  1.03576955e-04, -3.23976041e-04, -7.19415421e-04,\n",
       "       -1.78229041e-03,  2.49000982e-04, -2.21650401e-03, -3.06169997e-04,\n",
       "       -9.55295777e-04, -1.91761990e-03, -2.25250947e-03])\n",
       " message: 'Linear search failed'\n",
       "    nfev: 208\n",
       "     nit: 14\n",
       "  status: 4\n",
       " success: False\n",
       "       x: array([ 0.04099282,  0.12540757,  0.14371322,  0.04140441,  0.06421748,\n",
       "       -0.55177176, -0.37144562, -0.3545574 ,  0.64081805,  0.62851591,\n",
       "        2.49150711,  1.03718361,  1.1809878 , -1.73593536, -2.25308028,\n",
       "        0.10995667,  0.11582346,  0.21809978, -0.3497531 , -0.21800254,\n",
       "       -0.64418798, -0.42409275, -0.36102146,  0.71957096,  0.75487937,\n",
       "        0.10896535,  0.10253702,  0.0957077 ,  0.03259563,  0.02031255,\n",
       "       -0.65370581, -0.51051985, -0.49797896,  0.80706053,  0.77948447,\n",
       "        0.25444152,  0.07003903,  0.57001641, -1.01159994, -0.37452048,\n",
       "       -0.68279033, -0.39445806, -0.4006718 ,  0.67116466,  0.73120171,\n",
       "        0.11819373,  0.11864702,  0.12382218, -0.28940043, -0.24834496,\n",
       "       -0.36187081, -0.16442142, -0.83092646,  1.39856143,  0.59596284,\n",
       "        0.14232939,  0.11195328,  0.62140267, -1.04770162, -0.40478921,\n",
       "        0.43383988,  0.09334996,  0.61341752, -1.02302792, -0.49040494,\n",
       "        1.78085177,  0.88811747,  0.88054741, -1.41109209, -1.71294446,\n",
       "        0.11915346, -0.06838176,  0.14872634, -0.35480539, -0.124747  ,\n",
       "       -0.23936446, -0.58661075, -0.23268977, -0.38995841, -0.09912325,\n",
       "        0.1497155 ,  0.1283286 ,  0.42074362, -0.85672935, -0.34316006,\n",
       "        0.02836707,  0.02244657,  0.36807051, -0.64115956, -0.25063775,\n",
       "       -0.02997229,  0.1925696 ,  0.13327098,  0.11141072,  0.05394183,\n",
       "        0.41051536,  0.12847872,  0.75232173, -1.30546106, -0.50689692,\n",
       "       -0.42476223, -0.27215212, -0.29383543,  0.56411735,  0.50542243,\n",
       "        0.24182422,  0.1432399 ,  0.77690838, -1.26919322, -0.52406965,\n",
       "        0.24581163,  0.060692  ,  0.35867009, -0.66299656, -0.32165308,\n",
       "       -0.70461271, -0.52169511, -0.41202383,  0.80774674,  0.79190995,\n",
       "       -0.10050622,  0.08228731,  0.072305  ,  0.10831213,  0.05888498,\n",
       "       -0.42235969, -0.32439567, -0.67402611, -0.08314541,  0.30360913,\n",
       "       -0.73094148, -0.35607138, -0.62092618,  0.68633864, -0.68705412,\n",
       "        0.17160426, -1.45218595,  0.72725652,  0.87559028,  0.18046216,\n",
       "        0.266115  , -0.12112797,  0.85572982,  0.33643   , -0.30536096,\n",
       "        1.02141111, -0.76922518,  0.95286466,  0.60725238, -0.6508998 ,\n",
       "        0.01412037, -0.93579991, -0.30596569, -0.62065629,  2.89082213,\n",
       "        0.03922135, -0.6660613 , -0.27821463, -0.89020322, -0.96874425,\n",
       "       -0.64440025, -0.05550147,  1.75951333, -1.04942759, -1.1436596 ,\n",
       "        2.33801385, -0.16776933, -0.24724853, -0.86770863, -0.55476513,\n",
       "       -0.34930779, -1.64869135, -0.31993861, -1.50816979, -0.42709217,\n",
       "       -0.84556331, -0.21564671, -0.70857663,  0.18943434,  0.86456667,\n",
       "       -2.32027105, -0.58024078,  0.8501655 ,  0.01394433,  0.89066081,\n",
       "       -0.32112402,  1.19221506, -0.34836001,  0.13014245, -0.24921119,\n",
       "       -0.29000042, -2.41812156, -0.25524158,  0.00898518, -0.37741497,\n",
       "       -0.41801666,  0.16751377, -0.157034  ,  0.68306606, -0.2571645 ,\n",
       "       -0.52862811,  1.06304196,  0.11741458])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Minimizar la función objetivo que acabamos de definir\n",
    "fmin = minimize(fun=backpropReg, x0=params, args=(input_size, hidden_size, num_labels, X, y_onehot, lambda_reg), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempaquetamos los parámetros obtenidos como resultado del entrenamiento almacenados en fmin.x\n",
    "# Crea las variables theta1 y theta2\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "# Utilizamos los parámetros desempaquetados con la propagación hacia adelante para obtener la predicción para nuestros ejemplos\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "\n",
    "# Finalmente, para obtener la clase para cada ejemplo, buscamos de las diez salidas cual es la más alta\n",
    "# y usamos su índice como valor predicho (utilizar np.argmax con axis=1 que hace precísamente eso).\n",
    "y_pred = np.argmax(h,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en train: 98.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "accTrain = metrics.accuracy_score(y_pred, y)\n",
    "\n",
    "print(\"Precisión en train: {}%\".format(accTrain*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37vision] *",
   "language": "python",
   "name": "conda-env-py37vision-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
